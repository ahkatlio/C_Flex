import numpy as np

def getFFT(data, rate, chunk_size, log_scale=False):
    data = data * np.hamming(len(data))
    try:
        FFT = np.abs(np.fft.rfft(data)[1:])
    except:
        FFT = np.fft.fft(data)
        left, right = np.split(np.abs(FFT), 2)
        FFT = np.add(left, right[::-1])

    #fftx = np.fft.fftfreq(chunk_size, d=1.0/rate)
    #fftx = np.split(np.abs(fftx), 2)[0]

    if log_scale:
        try:
            FFT = np.multiply(20, np.log10(FFT))
        except Exception as e:
            print('Log(FFT) failed: %s' %str(e))

    return FFT


## TODO: Realtime Harmonic/Percussive decomposition

'''
from scipy import signal
def median_filter_horizontal(x, filter_len):
    return signal.medfilt(x, [1, filter_len])

def median_filter_vertical(x, filter_len):
    return signal.medfilt(x, [filter_len, 1])

def harmonic_percussive_decomposition(FFT_features, Fs):
    # https://www.audiolabs-erlangen.de/resources/MIR/FMP/C8/C8S1_HPS.html

    N, H = 1024, 512
    X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, window='hann', center=True, pad_mode='constant')
    Y = np.abs(X)**2

    L_set = np.array([[5,5],[23,9],[87,47]])
    num = L_set.shape[0]
    for m in range(num):
        L_h = L_set[m,0]
        L_p = L_set[m,1]
        Y_h = median_filter_horizontal(Y, L_h)
        Y_p = median_filter_vertical(Y, L_p)
        title_h = r'Horizontal filtering ($L^h=%d$)'%L_h
        title_p = r'Vertical filtering ($L^p=%d$)'%L_p
        plot_spectrogram_hp(Y_h, Y_p, Fs=Fs, N=N, H=H, title_h=title_h, title_p=title_p, ylim=[0, 3000], log=True)
'''

import numpy as np
import time, math, scipy
from collections import deque
from scipy.signal import savgol_filter

from src.fft import getFFT
from src.utils import *

class Stream_Analyzer:
    """
    The Audio_Analyzer class provides access to continuously recorded
    (and mathematically processed) audio data.

    Arguments:

        device: int or None:      Select which audio stream to read .
        rate: float or None:      Sample rate to use. Defaults to something supported.
        FFT_window_size_ms: int:  Time window size (in ms) to use for the FFT transform
        updatesPerSecond: int:    How often to record new data.

    """

    def __init__(self,
        device = None,
        rate   = None,
        FFT_window_size_ms  = 50,
        updates_per_second  = 100,
        smoothing_length_ms = 50,
        n_frequency_bins    = 51,
        visualize = True,
        verbose   = False,
        height    = 450,
        window_ratio = 24/9):

        self.n_frequency_bins = n_frequency_bins
        self.rate = rate
        self.verbose = verbose
        self.visualize = visualize
        self.height = height
        self.window_ratio = window_ratio

        try:
            from src.stream_reader_pyaudio import Stream_Reader
            self.stream_reader = Stream_Reader(
                device  = device,
                rate    = rate,
                updates_per_second  = updates_per_second,
                verbose = verbose)
        except:
            from src.stream_reader_sounddevice import Stream_Reader
            self.stream_reader = Stream_Reader(
                device  = device,
                rate    = rate,
                updates_per_second  = updates_per_second,
                verbose = verbose)

        self.rate = self.stream_reader.rate

        #Custom settings:
        self.rolling_stats_window_s    = 20     # The axis range of the FFT features will adapt dynamically using a window of N seconds
        self.equalizer_strength        = 0.20   # [0-1] --> gradually rescales all FFT features to have the same mean
        self.apply_frequency_smoothing = True   # Apply a postprocessing smoothing filter over the FFT outputs

        if self.apply_frequency_smoothing:
            self.filter_width = round_up_to_even(0.03*self.n_frequency_bins) - 1
        if self.visualize:
            from src.visualizer import Spectrum_Visualizer

        self.FFT_window_size = round_up_to_even(self.rate * FFT_window_size_ms / 1000)
        self.FFT_window_size_ms = 1000 * self.FFT_window_size / self.rate
        self.fft  = np.ones(int(self.FFT_window_size/2), dtype=float)
        self.fftx = np.arange(int(self.FFT_window_size/2), dtype=float) * self.rate / self.FFT_window_size

        self.data_windows_to_buffer = math.ceil(self.FFT_window_size / self.stream_reader.update_window_n_frames)
        self.data_windows_to_buffer = max(1,self.data_windows_to_buffer)

        # Temporal smoothing:
        # Currently the buffer acts on the FFT_features (which are computed only occasionally eg 30 fps)
        # This is bad since the smoothing depends on how often the .get_audio_features() method is called...
        self.smoothing_length_ms = smoothing_length_ms
        if self.smoothing_length_ms > 0:
            self.smoothing_kernel = get_smoothing_filter(self.FFT_window_size_ms, self.smoothing_length_ms, verbose=1)
            self.feature_buffer = numpy_data_buffer(len(self.smoothing_kernel), len(self.fft), dtype = np.float32, data_dimensions = 2)

        #This can probably be done more elegantly...
        self.fftx_bin_indices = np.logspace(np.log2(len(self.fftx)), 0, len(self.fftx), endpoint=True, base=2, dtype=None) - 1
        self.fftx_bin_indices = np.round(((self.fftx_bin_indices - np.max(self.fftx_bin_indices))*-1) / (len(self.fftx) / self.n_frequency_bins),0).astype(int)
        self.fftx_bin_indices = np.minimum(np.arange(len(self.fftx_bin_indices)), self.fftx_bin_indices - np.min(self.fftx_bin_indices))

        self.frequency_bin_energies = np.zeros(self.n_frequency_bins)
        self.frequency_bin_centres  = np.zeros(self.n_frequency_bins)
        self.fftx_indices_per_bin   = []
        for bin_index in range(self.n_frequency_bins):
            bin_frequency_indices = np.where(self.fftx_bin_indices == bin_index)
            self.fftx_indices_per_bin.append(bin_frequency_indices)
            fftx_frequencies_this_bin = self.fftx[bin_frequency_indices]
            self.frequency_bin_centres[bin_index] = np.mean(fftx_frequencies_this_bin)

        #Hardcoded parameters:
        self.fft_fps = 30
        self.log_features = False   # Plot log(FFT features) instead of FFT features --> usually pretty bad
        self.delays = deque(maxlen=20)
        self.num_ffts = 0
        self.strongest_frequency = 0

        #Assume the incoming sound follows a pink noise spectrum:
        self.power_normalization_coefficients = np.logspace(np.log2(1), np.log2(np.log2(self.rate/2)), len(self.fftx), endpoint=True, base=2, dtype=None)
        self.rolling_stats_window_n = self.rolling_stats_window_s * self.fft_fps #Assumes ~30 FFT features per second
        self.rolling_bin_values = numpy_data_buffer(self.rolling_stats_window_n, self.n_frequency_bins, start_value = 25000)
        self.bin_mean_values = np.ones(self.n_frequency_bins)

        print("Using FFT_window_size length of %d for FFT ---> window_size = %dms" %(self.FFT_window_size, self.FFT_window_size_ms))
        print("##################################################################################################")

        #Let's get started:
        self.stream_reader.stream_start(self.data_windows_to_buffer)

        if self.visualize:
            self.visualizer = Spectrum_Visualizer(self)
            self.visualizer.start()

    def update_rolling_stats(self):
        self.rolling_bin_values.append_data(self.frequency_bin_energies)
        self.bin_mean_values  = np.mean(self.rolling_bin_values.get_buffer_data(), axis=0)
        self.bin_mean_values  = np.maximum((1-self.equalizer_strength)*np.mean(self.bin_mean_values), self.bin_mean_values)

    def update_features(self, n_bins = 3):

        latest_data_window = self.stream_reader.data_buffer.get_most_recent(self.FFT_window_size)

        self.fft = getFFT(latest_data_window, self.rate, self.FFT_window_size, log_scale = self.log_features)
        #Equalize pink noise spectrum falloff:
        self.fft = self.fft * self.power_normalization_coefficients
        self.num_ffts += 1
        self.fft_fps  = self.num_ffts / (time.time() - self.stream_reader.stream_start_time)

        if self.smoothing_length_ms > 0:
            self.feature_buffer.append_data(self.fft)
            buffered_features = self.feature_buffer.get_most_recent(len(self.smoothing_kernel))
            if len(buffered_features) == len(self.smoothing_kernel):
                buffered_features = self.smoothing_kernel * buffered_features
                self.fft = np.mean(buffered_features, axis=0)

        self.strongest_frequency = self.fftx[np.argmax(self.fft)]

        #ToDo: replace this for-loop with pure numpy code
        for bin_index in range(self.n_frequency_bins):
            self.frequency_bin_energies[bin_index] = np.mean(self.fft[self.fftx_indices_per_bin[bin_index]])

        #Beat detection ToDo:
        #https://www.parallelcube.com/2018/03/30/beat-detection-algorithm/
        #https://github.com/shunfu/python-beat-detector
        #https://pypi.org/project/vamp/

        return

    def get_audio_features(self):

        if self.stream_reader.new_data:  #Check if the stream_reader has new audio data we need to process
            if self.verbose:
                start = time.time()

            self.update_features()
            self.update_rolling_stats()
            self.stream_reader.new_data = False

            self.frequency_bin_energies = np.nan_to_num(self.frequency_bin_energies, copy=True)
            if self.apply_frequency_smoothing:
                if self.filter_width > 3:
                    self.frequency_bin_energies = savgol_filter(self.frequency_bin_energies, self.filter_width, 3)
            self.frequency_bin_energies[self.frequency_bin_energies < 0] = 0

            if self.verbose:
                self.delays.append(time.time() - start)
                avg_fft_delay = 1000.*np.mean(np.array(self.delays))
                avg_data_capture_delay = 1000.*np.mean(np.array(self.stream_reader.data_capture_delays))
                data_fps = self.stream_reader.num_data_captures / (time.time() - self.stream_reader.stream_start_time)
                print("\nAvg fft  delay: %.2fms  -- avg data delay: %.2fms" %(avg_fft_delay, avg_data_capture_delay))
                print("Num data captures: %d (%.2ffps)-- num fft computations: %d (%.2ffps)"
                    %(self.stream_reader.num_data_captures, data_fps, self.num_ffts, self.fft_fps))

            if self.visualize and self.visualizer._is_running:
                self.visualizer.update()

        return self.fftx, self.fft, self.frequency_bin_centres, self.frequency_bin_energies

import numpy as np
import pyaudio
import time, sys, math
from collections import deque

from src.utils import *

class Stream_Reader:
    """
    The Stream_Reader continuously reads data from a selected sound source using PyAudio

    Arguments:

        device: int or None:    Select which audio stream to read .
        rate: float or None:    Sample rate to use. Defaults to something supported.
        updatesPerSecond: int:  How often to record new data.

    """

    def __init__(self,
        device = None,
        rate = None,
        updates_per_second  = 1000,
        FFT_window_size = None,
        verbose = False):

        self.rate = rate
        self.verbose = verbose
        self.pa = pyaudio.PyAudio()

        #Temporary variables #hacks!
        self.update_window_n_frames = 1024 #Don't remove this, needed for device testing!
        self.data_buffer = None

        self.device = device
        if self.device is None:
            self.device = self.input_device()
        if self.rate is None:
            self.rate = self.valid_low_rate(self.device)

        self.update_window_n_frames = round_up_to_even(self.rate / updates_per_second)
        self.updates_per_second = self.rate / self.update_window_n_frames
        self.info = self.pa.get_device_info_by_index(self.device)
        self.data_capture_delays = deque(maxlen=20)
        self.new_data = False
        if self.verbose:
            self.data_capture_delays = deque(maxlen=20)
            self.num_data_captures = 0

        self.stream = self.pa.open(
            input_device_index=self.device,
            format = pyaudio.paInt16,
            channels = 1,
            rate = self.rate,
            input=True,
            frames_per_buffer = self.update_window_n_frames,
            stream_callback=self.non_blocking_stream_read)

        print("\n##################################################################################################")
        print("\nDefaulted to using first working mic, Running on:")
        self.print_mic_info(self.device)
        print("\n##################################################################################################")
        print('Recording from %s at %d Hz\nUsing (non-overlapping) data-windows of %d samples (updating at %.2ffps)'
            %(self.info["name"],self.rate, self.update_window_n_frames, self.updates_per_second))

    def non_blocking_stream_read(self, in_data, frame_count, time_info, status):
        if self.verbose:
            start = time.time()

        if self.data_buffer is not None:
            self.data_buffer.append_data(np.frombuffer(in_data, dtype=np.int16))
            self.new_data = True

        if self.verbose:
            self.num_data_captures += 1
            self.data_capture_delays.append(time.time() - start)

        return in_data, pyaudio.paContinue

    def stream_start(self, data_windows_to_buffer = None):
        self.data_windows_to_buffer = data_windows_to_buffer

        if data_windows_to_buffer is None:
            self.data_windows_to_buffer = int(self.updates_per_second / 2) #By default, buffer 0.5 second of audio
        else:
            self.data_windows_to_buffer = int(data_windows_to_buffer)

        self.data_buffer = numpy_data_buffer(self.data_windows_to_buffer, self.update_window_n_frames)

        print("\n-- Starting live audio stream...\n")
        self.stream.start_stream()
        self.stream_start_time = time.time()

    def terminate(self):
        print("Sending stream termination command...")
        self.stream.stop_stream()
        self.stream.close()
        self.pa.terminate()

    def valid_low_rate(self, device, test_rates = [44100, 22050]):
        """Set the rate to the lowest supported audio rate."""
        for testrate in test_rates:
            if self.test_device(device, rate=testrate):
                return testrate

        #If none of the test_rates worked, try the default rate:
        self.info = self.pa.get_device_info_by_index(device)
        default_rate = int(self.info["defaultSampleRate"])

        if self.test_device(device, rate=default_rate):
            return default_rate

        print("SOMETHING'S WRONG! I can't figure out a good sample-rate for DEVICE =>", device)
        return default_rate

    def test_device(self, device, rate=None):
        """given a device ID and a rate, return True/False if it's valid."""
        try:
            self.info = self.pa.get_device_info_by_index(device)
            if not self.info["maxInputChannels"] > 0:
                return False

            if rate is None:
                rate = int(self.info["defaultSampleRate"])

            stream = self.pa.open(
                format = pyaudio.paInt16,
                channels = 1,
                input_device_index=device,
                frames_per_buffer=self.update_window_n_frames,
                rate = rate,
                input = True)
            stream.close()
            return True
        except Exception as e:
            #print(e)
            return False

    def input_device(self):
        """
        See which devices can be opened for microphone input.
        Return the first valid device
        """
        mics=[]
        for device in range(self.pa.get_device_count()):
            if self.test_device(device):
                mics.append(device)

        if len(mics) == 0:
            print("No working microphone devices found!")
            sys.exit()

        print("Found %d working microphone device(s): " % len(mics))
        for mic in mics:
            self.print_mic_info(mic)

        return mics[0]

    def print_mic_info(self, mic):
        mic_info = self.pa.get_device_info_by_index(mic)
        print('\nMIC %s:' %(str(mic)))
        for k, v in sorted(mic_info.items()):
            print("%s: %s" %(k, v))

import numpy as np
import time, sys, math
from collections import deque
import sounddevice as sd

from src.utils import *

class Stream_Reader:
    """
    The Stream_Reader continuously reads data from a selected sound source using PyAudio

    Arguments:

        device: int or None:    Select which audio stream to read .
        rate: float or None:    Sample rate to use. Defaults to something supported.
        updatesPerSecond: int:  How often to record new data.

    """

    def __init__(self,
        device = None,
        rate = None,
        updates_per_second  = 1000,
        FFT_window_size = None,
        verbose = False):

        print("Available audio devices:")
        device_dict = sd.query_devices()
        print(device_dict)

        try:
            sd.check_input_settings(device=device, channels=1, dtype=np.float32, extra_settings=None, samplerate=rate)
        except:
            print("Input sound settings for device %s and samplerate %s Hz not supported, using defaults..." %(str(device), str(rate)))
            rate = None
            device = None

        self.rate = rate
        if rate is not None:
            sd.default.samplerate = rate

        self.device = device
        if device is not None:
            sd.default.device = device

        self.verbose = verbose
        self.data_buffer = None

        # This part is a bit hacky, need better solution for this:
        # Determine what the optimal buffer shape is by streaming some test audio
        self.optimal_data_lengths = []
        with sd.InputStream(samplerate=self.rate,
                            blocksize=0,
                            device=self.device,
                            channels=1,
                            dtype=np.float32,
                            latency='low',
                            callback=self.test_stream_read):
            time.sleep(0.2)

        self.update_window_n_frames = max(self.optimal_data_lengths)
        del self.optimal_data_lengths

        #Alternative:
        #self.update_window_n_frames = round_up_to_even(44100 / updates_per_second)

        self.stream = sd.InputStream(
                                    samplerate=self.rate,
                                    blocksize=self.update_window_n_frames,
                                    device=None,
                                    channels=1,
                                    dtype=np.float32,
                                    latency='low',
                                    extra_settings=None,
                                    callback=self.non_blocking_stream_read)

        self.rate = self.stream.samplerate
        self.device = self.stream.device

        self.updates_per_second = self.rate / self.update_window_n_frames
        self.info = ''
        self.data_capture_delays = deque(maxlen=20)
        self.new_data = False
        if self.verbose:
            self.data_capture_delays = deque(maxlen=20)
            self.num_data_captures = 0

        self.device_latency = device_dict[self.device]['default_low_input_latency']

        print("\n##################################################################################################")
        print("\nDefaulted to using first working mic, Running on mic %s with properties:" %str(self.device))
        print(device_dict[self.device])
        print('Which has a latency of %.2f ms' %(1000*self.device_latency))
        print("\n##################################################################################################")
        print('Recording audio at %d Hz\nUsing (non-overlapping) data-windows of %d samples (updating at %.2ffps)'
            %(self.rate, self.update_window_n_frames, self.updates_per_second))

    def non_blocking_stream_read(self, indata, frames, time_info, status):
        if self.verbose:
            start = time.time()
            if status:
                print(status)

        if self.data_buffer is not None:
            self.data_buffer.append_data(indata[:,0])
            self.new_data = True

        if self.verbose:
            self.num_data_captures += 1
            self.data_capture_delays.append(time.time() - start)

        return

    def test_stream_read(self, indata, frames, time_info, status):
        '''
        Dummy function to determine what blocksize the stream is using
        '''
        self.optimal_data_lengths.append(len(indata[:,0]))
        return

    def stream_start(self, data_windows_to_buffer = None):
        self.data_windows_to_buffer = data_windows_to_buffer

        if data_windows_to_buffer is None:
            self.data_windows_to_buffer = int(self.updates_per_second / 2) #By default, buffer 0.5 second of audio
        else:
            self.data_windows_to_buffer = int(data_windows_to_buffer)

        self.data_buffer = numpy_data_buffer(self.data_windows_to_buffer, self.update_window_n_frames)

        print("\n--🎙  -- Starting live audio stream...\n")
        self.stream.start()
        self.stream_start_time = time.time()

    def terminate(self):
        print("👋  Sending stream termination command...")
        self.stream.stop()
    
    import numpy as np
import math, scipy, pygame

def round_up_to_even(f):
    return int(math.ceil(f / 2.) * 2)

def round_to_nearest_power_of_two(f, base=2):
    l = math.log(f,base)
    rounded = int(np.round(l,0))
    return base**rounded

def get_frequency_bins(start, stop, n):
    octaves = np.logspace(log(start)/log(2), log(stop)/log(2), n, endpoint=True, base=2, dtype=None)
    return np.insert(octaves, 0, 0)

def gaussian_kernel1d(sigma, truncate=2.0):
    sigma = float(sigma)
    sigma2 = sigma * sigma
    # make the radius of the filter equal to truncate standard deviations
    radius = int(truncate * sigma + 0.5)
    exponent_range = np.arange(1)

    x = np.arange(-radius, radius+1)
    phi_x = np.exp(-0.5 / sigma2 * x ** 2)
    phi_x = phi_x / phi_x.sum()
    return phi_x

def gaussian_kernel_1D(w, sigma):
    sigma = sigma
    x = np.linspace(-sigma, sigma, w+1)
    kern1d = np.diff(scipy.stats.norm.cdf(x))
    return kern1d/kern1d.sum()

def get_smoothing_filter(FFT_window_size_ms, filter_length_ms, verbose = 0):
    buffer_length = round_up_to_even(filter_length_ms / FFT_window_size_ms)+1
    filter_sigma = buffer_length / 3  #How quickly the smoothing influence drops over the buffer length
    filter_weights = gaussian_kernel1d(filter_sigma)[:,np.newaxis]

    max_index = np.argmax(filter_weights)
    filter_weights = filter_weights[:max_index+1]
    filter_weights = filter_weights / np.mean(filter_weights)

    if verbose:
        min_fraction = 100*np.min(filter_weights)/np.max(filter_weights)
        print('\nApplying temporal smoothing to the FFT features...')
        print("Smoothing buffer contains %d FFT windows (sigma: %.3f) --> min_contribution: %.3f%%" %(buffer_length, filter_sigma, min_fraction))
        print("Filter weights:")
        for i, w in enumerate(filter_weights):
            print("%02d: %.3f" %(len(filter_weights)-i, w))

    return filter_weights

class numpy_data_buffer:
    """
    A fast, circular FIFO buffer in numpy with minimal memory interactions by using an array of index pointers
    """

    def __init__(self, n_windows, samples_per_window, dtype = np.float32, start_value = 0, data_dimensions = 1):
        self.n_windows = n_windows
        self.data_dimensions = data_dimensions
        self.samples_per_window = samples_per_window
        self.data = start_value * np.ones((self.n_windows, self.samples_per_window), dtype = dtype)

        if self.data_dimensions == 1:
            self.total_samples = self.n_windows * self.samples_per_window
        else:
            self.total_samples = self.n_windows

        self.elements_in_buffer = 0
        self.overwrite_index = 0

        self.indices = np.arange(self.n_windows, dtype=np.int32)
        self.last_window_id = np.max(self.indices)
        self.index_order = np.argsort(self.indices)

    def append_data(self, data_window):
        self.data[self.overwrite_index, :] = data_window

        self.last_window_id += 1
        self.indices[self.overwrite_index] = self.last_window_id
        self.index_order = np.argsort(self.indices)

        self.overwrite_index += 1
        self.overwrite_index = self.overwrite_index % self.n_windows

        self.elements_in_buffer += 1
        self.elements_in_buffer = min(self.n_windows, self.elements_in_buffer)

    def get_most_recent(self, window_size):
        ordered_dataframe = self.data[self.index_order]
        if self.data_dimensions == 1:
            ordered_dataframe = np.hstack(ordered_dataframe)
        return ordered_dataframe[self.total_samples - window_size:]

    def get_buffer_data(self):
        return self.data[:self.elements_in_buffer]

class Button:
    def __init__(self, text="", right=10, top=30, width=None, height=20):
        self.text = text
        self.top = top
        self.height = height
        self.colour1 = (220, 220, 220)  # main
        self.colour2 = (100, 100, 100)  # border
        self.colour3 = (172, 220, 247)  # hover
        self.colour4 = (225, 243, 252)
        self.fontname = "freesansbold.ttf"
        self.fontsize = self.height-6
        self.mouse_over = False
        self.mouse_down = False
        self.mouse = "off"
        self.clicked = False
        self.pyg = pygame
        self.font = pygame.font.SysFont(self.fontname, self.fontsize)
        self.text_width, self.text_height = self.pyg.font.Font.size(self.font, self.text)
        if width == None:
            self.width = int(self.text_width * 1.3)
            self.width_type = "text"
        else:
            self.width = width
            self.width_type = "user"

        self.left = right - self.width
        self.buttonUP = self.pyg.Surface((self.width, self.height))
        self.buttonDOWN = self.pyg.Surface((self.width, self.height))
        self.buttonHOVER = self.pyg.Surface((self.width, self.height))
        self.__update__()

    def __update__(self):
        # up
        r, g, b = self.colour1
        self.buttonUP.fill(self.colour1)
        self.pyg.draw.rect(self.buttonUP, (r+20, g+20, b+20), (0, 0, self.width, self.height/2), 0)
        self.pyg.draw.line(self.buttonUP, self.colour2, (2, 0), (self.width-3, 0), 1)
        self.pyg.draw.line(self.buttonUP, self.colour2, (2, self.height-1), (self.width-3, self.height-1), 1)
        self.pyg.draw.line(self.buttonUP, self.colour2, (0, 2), (0, self.height-3), 1)
        self.pyg.draw.line(self.buttonUP, self.colour2, (self.width-1, 2), (self.width-1, self.height-3), 1)
        self.buttonUP.set_at((1, 1), self.colour2)
        self.buttonUP.set_at((self.width-2, 1), self.colour2)
        self.buttonUP.set_at((1, self.height-2), self.colour2)
        self.buttonUP.set_at((self.width-2, self.height-2), self.colour2)
        self.buttonUP.blit(self.font.render(self.text, False, (0, 0, 0)), ((self.width/2)-(self.text_width/2), (self.height/2)-(self.text_height/2)))
        # hover
        self.buttonHOVER.fill(self.colour3)
        self.pyg.draw.rect(self.buttonHOVER, self.colour4, (0, 0, self.width, self.height/2), 0)
        self.pyg.draw.line(self.buttonHOVER, self.colour2, (2, 0), (self.width-3, 0), 1)
        self.pyg.draw.line(self.buttonHOVER, self.colour2, (2, self.height-1), (self.width-3, self.height-1), 1)
        self.pyg.draw.line(self.buttonHOVER, self.colour4, (2, self.height-2), (self.width-3, self.height-2), 1)
        self.pyg.draw.line(self.buttonHOVER, self.colour2, (0, 2), (0, self.height-3), 1)
        self.pyg.draw.line(self.buttonHOVER, self.colour4, (1, 2), (1, self.height-3), 2)
        self.pyg.draw.line(self.buttonHOVER, self.colour2, (self.width-1, 2), (self.width-1, self.height-3), 1)
        self.buttonHOVER.set_at((1, 1), self.colour2)
        self.buttonHOVER.set_at((self.width-2, 1), self.colour2)
        self.buttonHOVER.set_at((1, self.height-2), self.colour2)
        self.buttonHOVER.set_at((self.width-2, self.height-2), self.colour2)
        self.buttonHOVER.blit(self.font.render(self.text, False, (0, 0, 0)), ((self.width/2)-(self.text_width/2), (self.height/2)-(self.text_height/2)))
        # down
        r, g, b = self.colour3
        r2, g2, b2 = self.colour4
        self.buttonDOWN.fill((r-20, g-20, b-10))
        self.pyg.draw.rect(self.buttonDOWN, (r2-20, g2-20, b2-10), (0, 0, self.width, self.height/2), 0)
        self.pyg.draw.line(self.buttonDOWN, self.colour2, (2, 0), (self.width-3, 0), 1)
        self.pyg.draw.line(self.buttonDOWN, (r-20, g-20, b-10), (2, 1), (self.width-3, 1), 2)
        self.pyg.draw.line(self.buttonDOWN, self.colour2, (2, self.height-1), (self.width-3, self.height-1), 1)
        self.pyg.draw.line(self.buttonDOWN, self.colour2, (0, 2), (0, self.height-3), 1)
        self.pyg.draw.line(self.buttonDOWN, (r-20, g-20, b-10), (1, 2), (1, self.height-3), 2)
        self.pyg.draw.line(self.buttonDOWN, self.colour2, (self.width-1, 2), (self.width-1, self.height-3), 1)
        self.buttonDOWN.set_at((1, 1), self.colour2)
        self.buttonDOWN.set_at((self.width-2, 1), self.colour2)
        self.buttonDOWN.set_at((1, self.height-2), self.colour2)
        self.buttonDOWN.set_at((self.width-2, self.height-2), self.colour2)
        self.buttonDOWN.blit(self.font.render(self.text, False, (0, 0, 0)), ((self.width/2)-(self.text_width/2)+1, (self.height/2)-(self.text_height/2)))

    def draw(self, surface):
        self.__mouse_check__()
        if self.mouse == "hover":
            surface.blit(self.buttonHOVER, (self.left, self.top))
        elif self.mouse == "off":
            surface.blit(self.buttonUP, (self.left, self.top))
        elif self.mouse == "down":
            surface.blit(self.buttonDOWN, (self.left, self.top))

    def __mouse_check__(self):
        _1, _2, _3 = pygame.mouse.get_pressed()
        mouse_x, mouse_y = pygame.mouse.get_pos()
        if not _1:
            self.mouse = "off"
        if mouse_x > self.left and mouse_x < self.left + self.width and mouse_y > self.top and mouse_y < self.top + self.height and not self.mouse == "down":
            self.mouse = "hover"
        if not self.mouse_down and _1 and self.mouse == "hover":
            self.mouse = "down"
            self.clicked = True
        if self.mouse == "off":
            self.clicked = False

    def click(self):
        _1, _2, _3 = pygame.mouse.get_pressed()
        mouse_x, mouse_y = pygame.mouse.get_pos()
        if mouse_x > self.left and mouse_x < self.left + self.width and mouse_y > self.top and mouse_y < self.top + self.height and self.clicked and not _1:
            self.clicked = False
            return True
        else:
            return False

    def set_text(self, text, fontname="Arial", fontsize=None):
        self.text = text
        self.fontname = fontname
        if not fontsize == None:
            self.fontsize = fontsize
        self.font = pygame.font.SysFont(self.fontname, self.fontsize)
        self.text_width, self.text_height = self.pyg.font.Font.size(self.font, self.text)
        if self.width_type == "text":
            self.width = self.text_width + 20
        self.buttonUP = self.pyg.Surface((self.width, self.height))
        self.buttonDOWN = self.pyg.Surface((self.width, self.height))
        self.buttonHOVER = self.pyg.Surface((self.width, self.height))
        self.__update__()

import numpy as np
import time, sys, math
import pygame
from collections import deque
from src.utils import Button
from matplotlib import cm

class Spectrum_Visualizer:
    """
    The Spectrum_Visualizer visualizes spectral FFT data using a simple PyGame GUI
    """
    def __init__(self, ear):
        self.plot_audio_history = True
        self.ear = ear

        self.HEIGHT  = self.ear.height
        window_ratio = self.ear.window_ratio

        self.HEIGHT = round(self.HEIGHT)
        self.WIDTH  = round(window_ratio*self.HEIGHT)
        self.y_ext = [round(0.05*self.HEIGHT), self.HEIGHT]
        self.cm = cm.plasma
        #self.cm = cm.inferno

        self.toggle_history_mode()

        self.add_slow_bars = 1
        self.add_fast_bars = 1
        self.slow_bar_thickness = max(0.00002*self.HEIGHT, 1.25 / self.ear.n_frequency_bins)
        self.tag_every_n_bins = max(1,round(5 * (self.ear.n_frequency_bins / 51))) # Occasionally display Hz tags on the x-axis

        self.fast_bar_colors = [list((255*np.array(self.cm(i))[:3]).astype(int)) for i in np.linspace(0,255,self.ear.n_frequency_bins).astype(int)]
        self.slow_bar_colors = [list(np.clip((255*3.5*np.array(self.cm(i))[:3]).astype(int) , 0, 255)) for i in np.linspace(0,255,self.ear.n_frequency_bins).astype(int)]
        self.fast_bar_colors = self.fast_bar_colors[::-1]
        self.slow_bar_colors = self.slow_bar_colors[::-1]

        self.slow_features = [0]*self.ear.n_frequency_bins
        self.frequency_bin_max_energies  = np.zeros(self.ear.n_frequency_bins)
        self.frequency_bin_energies = self.ear.frequency_bin_energies
        self.bin_text_tags, self.bin_rectangles = [], []

        #Fixed init params:
        self.start_time = None
        self.vis_steps  = 0
        self.fps_interval = 10
        self.fps = 0
        self._is_running = False

    def toggle_history_mode(self):

        if self.plot_audio_history:
            self.bg_color           = 10    #Background color
            self.decay_speed        = 0.10  #Vertical decay of slow bars
            self.inter_bar_distance = 0
            self.avg_energy_height  = 0.1125
            self.alpha_multiplier   = 0.995
            self.move_fraction      = 0.0099
            self.shrink_f           = 0.994

        else:
            self.bg_color           = 60
            self.decay_speed        = 0.06
            self.inter_bar_distance = int(0.2*self.WIDTH / self.ear.n_frequency_bins)
            self.avg_energy_height  = 0.225

        self.bar_width = (self.WIDTH / self.ear.n_frequency_bins) - self.inter_bar_distance

        #Configure the bars:
        self.slow_bars, self.fast_bars, self.bar_x_positions = [],[],[]
        for i in range(self.ear.n_frequency_bins):
            x = int(i* self.WIDTH / self.ear.n_frequency_bins)
            fast_bar = [int(x), int(self.y_ext[0]), math.ceil(self.bar_width), None]
            slow_bar = [int(x), None, math.ceil(self.bar_width), None]
            self.bar_x_positions.append(x)
            self.fast_bars.append(fast_bar)
            self.slow_bars.append(slow_bar)

    def start(self):
        print("Starting spectrum visualizer...")
        pygame.init()
        self.screen = pygame.display.set_mode((self.WIDTH, self.HEIGHT))
        self.screen.fill((self.bg_color,self.bg_color,self.bg_color))

        if self.plot_audio_history:
            self.screen.set_alpha(255)
            self.prev_screen = self.screen

        pygame.display.set_caption('Spectrum Analyzer -- (FFT-Peak: %05d Hz)' %self.ear.strongest_frequency)
        self.bin_font = pygame.font.Font('freesansbold.ttf', round(0.025*self.HEIGHT))
        self.fps_font = pygame.font.Font('freesansbold.ttf', round(0.05*self.HEIGHT))

        for i in range(self.ear.n_frequency_bins):
            if i == 0 or i == (self.ear.n_frequency_bins - 1):
                continue
            if i % self.tag_every_n_bins == 0:
                f_centre = self.ear.frequency_bin_centres[i]
                text = self.bin_font.render('%d Hz' %f_centre, True, (255, 255, 255) , (self.bg_color, self.bg_color, self.bg_color))
                textRect = text.get_rect()
                x = i*(self.WIDTH / self.ear.n_frequency_bins) + (self.bar_width - textRect.x)/2
                y = 0.98*self.HEIGHT
                textRect.center = (int(x),int(y))
                self.bin_text_tags.append(text)
                self.bin_rectangles.append(textRect)

        self._is_running = True

        #Interactive components:
        self.button_height = round(0.05*self.HEIGHT)
        self.history_button  = Button(text="Toggle 2D/3D Mode", right=self.WIDTH, top=0, width=round(0.12*self.WIDTH), height=self.button_height)
        self.slow_bar_button = Button(text="Toggle Slow Bars", right=self.WIDTH, top=self.history_button.height, width=round(0.12*self.WIDTH), height=self.button_height)

    def stop(self):
        print("Stopping spectrum visualizer...")
        del self.fps_font
        del self.bin_font
        del self.screen
        del self.prev_screen
        pygame.quit()
        self._is_running = False

    def toggle_display(self):
        '''
        This function can be triggered to turn on/off the display
        '''
        if self._is_running: self.stop()
        else: self.start()

    def update(self):
        for event in pygame.event.get():
            if self.history_button.click():
                self.plot_audio_history = not self.plot_audio_history
                self.toggle_history_mode()
            if self.slow_bar_button.click():
                self.add_slow_bars = not self.add_slow_bars
                self.slow_features = [0]*self.ear.n_frequency_bins

        if np.min(self.ear.bin_mean_values) > 0:
            self.frequency_bin_energies = self.avg_energy_height * self.ear.frequency_bin_energies / self.ear.bin_mean_values

        if self.plot_audio_history:
            new_w, new_h = int((2+self.shrink_f)/3*self.WIDTH), int(self.shrink_f*self.HEIGHT)
            #new_w, new_h = int(self.shrink_f*self.WIDTH), int(self.shrink_f*self.HEIGHT)

            horizontal_pixel_difference = self.WIDTH - new_w
            prev_screen = pygame.transform.scale(self.prev_screen, (new_w, new_h))

        self.screen.fill((self.bg_color,self.bg_color,self.bg_color))

        if self.plot_audio_history:
            new_pos = int(self.move_fraction*self.WIDTH - (0.0133*self.WIDTH)), int(self.move_fraction*self.HEIGHT)
            self.screen.blit(pygame.transform.rotate(prev_screen, 180), new_pos)

        if self.start_time is None:
           self.start_time = time.time()

        self.vis_steps += 1

        if self.vis_steps%self.fps_interval == 0:
            self.fps = self.fps_interval / (time.time()-self.start_time)
            self.start_time = time.time()

        self.text = self.fps_font.render('Fps: %.1f' %(self.fps), True, (255, 255, 255) , (self.bg_color, self.bg_color, self.bg_color))
        self.textRect = self.text.get_rect()
        self.textRect.x, self.textRect.y = round(0.015*self.WIDTH), round(0.03*self.HEIGHT)
        pygame.display.set_caption('Spectrum Analyzer -- (FFT-Peak: %05d Hz)' %self.ear.strongest_frequency)

        self.plot_bars()

        #Draw text tags:
        self.screen.blit(self.text, self.textRect)
        if len(self.bin_text_tags) > 0:
            cnt = 0
            for i in range(self.ear.n_frequency_bins):
                if i == 0 or i == (self.ear.n_frequency_bins - 1):
                    continue
                if i % self.tag_every_n_bins == 0:
                    self.screen.blit(self.bin_text_tags[cnt], self.bin_rectangles[cnt])
                    cnt += 1

        self.history_button.draw(self.screen)
        self.slow_bar_button.draw(self.screen)

        pygame.display.flip()


    def plot_bars(self):
        bars, slow_bars, new_slow_features = [], [], []
        local_height = self.y_ext[1] - self.y_ext[0]
        feature_values = self.frequency_bin_energies[::-1]

        for i in range(len(self.frequency_bin_energies)):
            feature_value = feature_values[i] * local_height

            self.fast_bars[i][3] = int(feature_value)

            if self.plot_audio_history:
                self.fast_bars[i][3] = int(feature_value + 0.02*self.HEIGHT)

            if self.add_slow_bars:
                self.decay = min(0.99, 1 - max(0,self.decay_speed * 60 / self.ear.fft_fps))
                slow_feature_value = max(self.slow_features[i]*self.decay, feature_value)
                new_slow_features.append(slow_feature_value)
                self.slow_bars[i][1] = int(self.fast_bars[i][1] + slow_feature_value)
                self.slow_bars[i][3] = int(self.slow_bar_thickness * local_height)

        if self.add_fast_bars:
            for i, fast_bar in enumerate(self.fast_bars):
                pygame.draw.rect(self.screen,self.fast_bar_colors[i],fast_bar,0)

        if self.plot_audio_history:
                self.prev_screen = self.screen.copy().convert_alpha()
                self.prev_screen = pygame.transform.rotate(self.prev_screen, 180)
                self.prev_screen.set_alpha(self.prev_screen.get_alpha()*self.alpha_multiplier)

        if self.add_slow_bars:
            for i, slow_bar in enumerate(self.slow_bars):
                pygame.draw.rect(self.screen,self.slow_bar_colors[i],slow_bar,0)

        self.slow_features = new_slow_features

        #Draw everything:
        self.screen.blit(pygame.transform.rotate(self.screen, 180), (0, 0))